{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bengaluru data shape: (13320, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13320 entries, 0 to 13319\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   area_type     13320 non-null  object \n",
      " 1   availability  13320 non-null  object \n",
      " 2   location      13319 non-null  object \n",
      " 3   size          13304 non-null  object \n",
      " 4   society       7818 non-null   object \n",
      " 5   total_sqft    13320 non-null  object \n",
      " 6   bath          13247 non-null  float64\n",
      " 7   balcony       12711 non-null  float64\n",
      " 8   price         13320 non-null  float64\n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 936.7+ KB\n",
      "\n",
      "First 5 rows of Indian Housing Data:\n",
      "              area_type   availability                  location       size  \\\n",
      "0  Super built-up  Area         19-Dec  Electronic City Phase II      2 BHK   \n",
      "1            Plot  Area  Ready To Move          Chikka Tirupathi  4 Bedroom   \n",
      "2        Built-up  Area  Ready To Move               Uttarahalli      3 BHK   \n",
      "3  Super built-up  Area  Ready To Move        Lingadheeranahalli      3 BHK   \n",
      "4  Super built-up  Area  Ready To Move                  Kothanur      2 BHK   \n",
      "\n",
      "   society total_sqft  bath  balcony   price  \n",
      "0  Coomee        1056   2.0      1.0   39.07  \n",
      "1  Theanmp       2600   5.0      3.0  120.00  \n",
      "2      NaN       1440   2.0      3.0   62.00  \n",
      "3  Soiewre       1521   3.0      1.0   95.00  \n",
      "4      NaN       1200   2.0      1.0   51.00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# --- STEP 1: Data Loading ---\n",
    "# Load the single dataset file (assuming you named it 'Bengaluru_House_Data.csv')\n",
    "df = pd.read_csv('data/Bengaluru_House_Data.csv') \n",
    "\n",
    "# Display initial info\n",
    "print(f\"Bengaluru data shape: {df.shape}\")\n",
    "df.info()\n",
    "print(\"\\nFirst 5 rows of Indian Housing Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# --- STEP 2: Initial Cleaning and Feature Selection (EDA) ---\n",
    "\n",
    "# 2.1 Drop irrelevant features\n",
    "# 'area_type', 'availability', 'society', and 'balcony' are often messy or irrelevant for a beginner model.\n",
    "df.drop(['area_type', 'availability', 'society', 'balcony'], axis='columns', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after dropping NaNs: 13246 (Lost 74 rows)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Drop NaNs\n",
    "initial_rows = df.shape[0] # Saving initial count for comparison\n",
    "\n",
    "# FIX APPLIED HERE: Create a single boolean mask across all features (df) and apply it to Y_target\n",
    "rows_to_keep_simple_nan = df.notnull().all(axis=1)\n",
    "\n",
    "df = df[rows_to_keep_simple_nan].reset_index(drop=True)\n",
    "Y_target = Y_target[rows_to_keep_simple_nan].reset_index(drop=True)\n",
    "\n",
    "print(f\"Total rows after dropping NaNs: {df.shape[0]} (Lost {initial_rows - df.shape[0]} rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows after dropping NaNs: 13246 (Lost 74 rows)\n",
      "\n",
      "'bhk' column created and 'size' column dropped.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTotal rows after dropping NaNs: {df.shape[0]} (Lost {initial_rows - df.shape[0]} rows)\")\n",
    "\n",
    "# --- Step 4A: Feature Engineering - Cleaning 'size' (BHK) ---\n",
    "\n",
    "# Create a clean numerical 'bhk' column by extracting the number from the 'size' string\n",
    "# The function extracts the first part of the string, which is the number of bedrooms/BHK.\n",
    "df['bhk'] = df['size'].apply(lambda x: int(x.split(' ')[0]))\n",
    "\n",
    "# Drop the messy original 'size' column\n",
    "df.drop('size', axis='columns', inplace=True)\n",
    "\n",
    "print(\"\\n'bhk' column created and 'size' column dropped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after cleaning total_sqft errors: 13200 (Lost 46 rows)\n"
     ]
    }
   ],
   "source": [
    "# Step 4B: Clean total_sqft\n",
    "def convert_sqft_to_num(x):\n",
    "    tokens = str(x).split('-')\n",
    "    if len(tokens) == 2:\n",
    "        return (float(tokens[0]) + float(tokens[1])) / 2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['total_sqft'] = df['total_sqft'].apply(convert_sqft_to_num)\n",
    "# Drop remaining NaNs (failed conversions)\n",
    "# --- FIX: Use index-aligned boolean mask for dropping ---\n",
    "initial_rows_sqft = df.shape[0]\n",
    "rows_to_keep = df['total_sqft'].notnull()\n",
    "\n",
    "df = df[rows_to_keep].reset_index(drop=True)\n",
    "Y_target = Y_target[rows_to_keep].reset_index(drop=True)\n",
    "\n",
    "print(f\"Total rows after cleaning total_sqft errors: {df.shape[0]} (Lost {initial_rows_sqft - df.shape[0]} rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'price_per_sqft' feature successfully created.\n",
      "                   location  total_sqft  bath   price  bhk  price_per_sqft\n",
      "0  Electronic City Phase II      1056.0   2.0   39.07    2     6060.606061\n",
      "1          Chikka Tirupathi      2600.0   5.0  120.00    4     1807.692308\n",
      "2               Uttarahalli      1440.0   2.0   62.00    3     3750.000000\n",
      "3        Lingadheeranahalli      1521.0   3.0   95.00    3     2432.610125\n",
      "4                  Kothanur      1200.0   2.0   51.00    2     4166.666667\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Feature Engineering - Price Per Square Foot ---\n",
    "\n",
    "# CRITICAL STEP: Create a new feature for Outlier Analysis\n",
    "# Price is in Lakhs (â‚¹ 100,000), so we multiply by 100000 to get price in Rupees\n",
    "df['price_per_sqft'] = (Y_target * 100000) / df['total_sqft']\n",
    "\n",
    "print(\"\\n'price_per_sqft' feature successfully created.\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'price_per_sqft' feature successfully created and rounded.\n",
      "                   location  total_sqft  bath   price  bhk  price_per_sqft\n",
      "0  Electronic City Phase II      1056.0   2.0   39.07    2         6060.61\n",
      "1          Chikka Tirupathi      2600.0   5.0  120.00    4         1807.69\n",
      "2               Uttarahalli      1440.0   2.0   62.00    3         3750.00\n",
      "3        Lingadheeranahalli      1521.0   3.0   95.00    3         2432.61\n",
      "4                  Kothanur      1200.0   2.0   51.00    2         4166.67\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5B: rounded up values of 'total_sqft' to nearest integer ---\n",
    "# ADDED ROUNDING STEP HERE: Rounding to 2 decimal places for neatness\n",
    "df['price_per_sqft'] = df['price_per_sqft'].round(2)\n",
    "\n",
    "print(\"\\n'price_per_sqft' feature successfully created and rounded.\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6A: Outlier removal (BHK/Sqft ratio)\n",
    "initial_rows_outlier = df.shape[0]\n",
    "rows_to_keep_bhk = ~(df['total_sqft'] / df['bhk'] < 300)\n",
    "\n",
    "df = df[rows_to_keep_bhk].reset_index(drop=True)\n",
    "Y_target = Y_target[rows_to_keep_bhk].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows after Outlier Removal (sqft/bhk and price/sqft): 113 (Lost 13087 rows)\n"
     ]
    }
   ],
   "source": [
    "# Step 6B: Outlier removal (Price/Sqft by location)\n",
    "def remove_price_per_sqft_outliers(df_in, Y_in):\n",
    "    df_out = pd.DataFrame()\n",
    "    Y_out = pd.Series(dtype=np.float64) \n",
    "    \n",
    "    for key, subdf in df_in.groupby('location'):\n",
    "        m = np.mean(subdf['price_per_sqft'])\n",
    "        st = np.std(subdf['price_per_sqft'])\n",
    "        \n",
    "        # Filter the group\n",
    "        reduced_df = subdf[(subdf['price_per_sqft'] > (m - st)) & (subdf['price_per_sqft'] <= (m + st))]\n",
    "        \n",
    "        # Get the corresponding Y values\n",
    "        reduced_Y = Y_in.loc[reduced_df.index]\n",
    "        \n",
    "        # Concatenate results\n",
    "        df_out = pd.concat([df_out, reduced_df], ignore_index=False)\n",
    "        Y_out = pd.concat([Y_out, reduced_Y], ignore_index=False)\n",
    "        \n",
    "    return df_out.reset_index(drop=True), Y_out.reset_index(drop=True) # Reset index on final output\n",
    "\n",
    "df, Y_target = remove_price_per_sqft_outliers(df, Y_target) # Pass Y_target into the function\n",
    "\n",
    "print(f\"\\nRows after Outlier Removal (sqft/bhk and price/sqft): {df.shape[0]} (Lost {initial_rows_outlier - df.shape[0]} rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X) shape after encoding: (113, 50)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Feature Encoding (One-Hot Encoding for 'location')\n",
    "X = df.drop(['price_per_sqft'], axis='columns') \n",
    "X = pd.get_dummies(X, drop_first=True) \n",
    "\n",
    "print(f\"Features (X) shape after encoding: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (90, 50)\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Splitting and Transformation\n",
    "\n",
    "# Apply Log transformation to the Target (Y)\n",
    "Y = np.log1p(Y_target) \n",
    "\n",
    "# Split the data 80% for training, 20% for testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bengaluru data shape: (13320, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13320 entries, 0 to 13319\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   area_type     13320 non-null  object \n",
      " 1   availability  13320 non-null  object \n",
      " 2   location      13319 non-null  object \n",
      " 3   size          13304 non-null  object \n",
      " 4   society       7818 non-null   object \n",
      " 5   total_sqft    13320 non-null  object \n",
      " 6   bath          13247 non-null  float64\n",
      " 7   balcony       12711 non-null  float64\n",
      " 8   price         13320 non-null  float64\n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 936.7+ KB\n",
      "\n",
      "First 5 rows of Indian Housing Data:\n",
      "              area_type   availability                  location       size  \\\n",
      "0  Super built-up  Area         19-Dec  Electronic City Phase II      2 BHK   \n",
      "1            Plot  Area  Ready To Move          Chikka Tirupathi  4 Bedroom   \n",
      "2        Built-up  Area  Ready To Move               Uttarahalli      3 BHK   \n",
      "3  Super built-up  Area  Ready To Move        Lingadheeranahalli      3 BHK   \n",
      "4  Super built-up  Area  Ready To Move                  Kothanur      2 BHK   \n",
      "\n",
      "   society total_sqft  bath  balcony   price  \n",
      "0  Coomee        1056   2.0      1.0   39.07  \n",
      "1  Theanmp       2600   5.0      3.0  120.00  \n",
      "2      NaN       1440   2.0      3.0   62.00  \n",
      "3  Soiewre       1521   3.0      1.0   95.00  \n",
      "4      NaN       1200   2.0      1.0   51.00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# --- STEP 1: Data Loading ---\n",
    "# Load the single dataset file (assuming you named it 'Bengaluru_House_Data.csv')\n",
    "df = pd.read_csv('data/Bengaluru_House_Data.csv') \n",
    "\n",
    "# Display initial info\n",
    "print(f\"Bengaluru data shape: {df.shape}\")\n",
    "df.info()\n",
    "print(\"\\nFirst 5 rows of Indian Housing Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# --- STEP 2: Initial Cleaning and Feature Selection (EDA) ---\n",
    "\n",
    "# 2.1 Drop irrelevant features\n",
    "# 'area_type', 'availability', 'society', and 'balcony' are often messy or irrelevant for a beginner model.\n",
    "df.drop(['area_type', 'availability', 'society', 'balcony'], axis='columns', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows after dropping NaNs: 13200 (Lost 74 rows)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Handling Simple Missing Values (NaN) ---\n",
    "\n",
    "# Dropping rows with simple NaNs in the feature set (df)\n",
    "# For this dataset, dropping a few dozen rows is safer than complex imputation.\n",
    "initial_rows = df.shape[0]\n",
    "\n",
    "# Drop NaNs from the Feature Set (X)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# --- Keep Y_target Synchronized ---\n",
    "# Re-align Y_target to match the remaining rows in df\n",
    "# We find the new index of the cleaned df and apply it to Y_target\n",
    "Y_target = Y_target[df.index]\n",
    "\n",
    "print(f\"\\nTotal rows after dropping NaNs: {df.shape[0]} (Lost {initial_rows - df.shape[0]} rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows after dropping NaNs: 13200 (Lost 74 rows)\n",
      "\n",
      "'bhk' column created and 'size' column dropped.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTotal rows after dropping NaNs: {df.shape[0]} (Lost {initial_rows - df.shape[0]} rows)\")\n",
    "\n",
    "# --- Step 4A: Feature Engineering - Cleaning 'size' (BHK) ---\n",
    "\n",
    "# Create a clean numerical 'bhk' column by extracting the number from the 'size' string\n",
    "# The function extracts the first part of the string, which is the number of bedrooms/BHK.\n",
    "df['bhk'] = df['size'].apply(lambda x: int(x.split(' ')[0]))\n",
    "\n",
    "# Drop the messy original 'size' column\n",
    "df.drop('size', axis='columns', inplace=True)\n",
    "\n",
    "print(\"\\n'bhk' column created and 'size' column dropped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after cleaning total_sqft errors: 13200 (Lost 0 rows)\n",
      "\n",
      "'total_sqft' column is now fully numerical.\n",
      "                   location  total_sqft  bath  bhk\n",
      "0  Electronic City Phase II      1056.0   2.0    2\n",
      "1          Chikka Tirupathi      2600.0   5.0    4\n",
      "2               Uttarahalli      1440.0   2.0    3\n",
      "3        Lingadheeranahalli      1521.0   3.0    3\n",
      "4                  Kothanur      1200.0   2.0    2\n"
     ]
    }
   ],
   "source": [
    "# Assuming previous code is run, 'df' is the feature set and 'Y_target' is the price.\n",
    "\n",
    "# --- STEP 4B: Cleaning the 'total_sqft' column (FIXED) ---\n",
    "\n",
    "def convert_sqft_to_num(x):\n",
    "    # This function handles three cases: single number, range, or other units.\n",
    "    \n",
    "    # 1. Case: Range (e.g., \"1050 - 1100\")\n",
    "    tokens = str(x).split('-')\n",
    "    if len(tokens) == 2:\n",
    "        # Return the average of the range\n",
    "        try:\n",
    "            return (float(tokens[0]) + float(tokens[1])) / 2\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    # 2. Case: Single number (e.g., \"1056\")\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        # 3. Case: Other units (e.g., \"34.46Sq. Meter\") - return None\n",
    "        return None \n",
    "\n",
    "# Apply the function to the total_sqft column\n",
    "df['total_sqft'] = df['total_sqft'].apply(convert_sqft_to_num)\n",
    "\n",
    "# --- Synchronization FIX ---\n",
    "# Drop rows where the conversion failed (i.e., returned None/NaN in 'total_sqft')\n",
    "initial_rows = df.shape[0]\n",
    "\n",
    "# 1. Identify which rows need to be dropped\n",
    "rows_to_drop = df[df['total_sqft'].isnull()].index\n",
    "\n",
    "# 2. Drop the rows from the feature set (df)\n",
    "df.drop(rows_to_drop, inplace=True)\n",
    "\n",
    "# 3. Drop the EXACT SAME rows from the target variable (Y_target)\n",
    "Y_target.drop(rows_to_drop, inplace=True) \n",
    "# Note: We must drop using the index (rows_to_drop) to keep them aligned.\n",
    "\n",
    "print(f\"Total rows after cleaning total_sqft errors: {df.shape[0]} (Lost {initial_rows - df.shape[0]} rows)\")\n",
    "print(\"\\n'total_sqft' column is now fully numerical.\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'price_per_sqft' feature successfully created.\n",
      "                   location  total_sqft  bath  bhk  price_per_sqft\n",
      "0  Electronic City Phase II      1056.0   2.0    2     3699.810606\n",
      "1          Chikka Tirupathi      2600.0   5.0    4     4615.384615\n",
      "2               Uttarahalli      1440.0   2.0    3     4305.555556\n",
      "3        Lingadheeranahalli      1521.0   3.0    3     6245.890861\n",
      "4                  Kothanur      1200.0   2.0    2     4250.000000\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Feature Engineering - Price Per Square Foot ---\n",
    "\n",
    "# CRITICAL STEP: Create a new feature for Outlier Analysis\n",
    "# Price is in Lakhs (â‚¹ 100,000), so we multiply by 100000 to get price in Rupees\n",
    "df['price_per_sqft'] = (Y_target * 100000) / df['total_sqft']\n",
    "\n",
    "print(\"\\n'price_per_sqft' feature successfully created.\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'price_per_sqft' feature successfully created and rounded.\n",
      "                   location  total_sqft  bath  bhk  price_per_sqft\n",
      "0  Electronic City Phase II      1056.0   2.0    2         3699.81\n",
      "1          Chikka Tirupathi      2600.0   5.0    4         4615.38\n",
      "2               Uttarahalli      1440.0   2.0    3         4305.56\n",
      "3        Lingadheeranahalli      1521.0   3.0    3         6245.89\n",
      "4                  Kothanur      1200.0   2.0    2         4250.00\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5B: rounded up values of 'total_sqft' to nearest integer ---\n",
    "# ADDED ROUNDING STEP HERE: Rounding to 2 decimal places for neatness\n",
    "df['price_per_sqft'] = df['price_per_sqft'].round(2)\n",
    "\n",
    "print(\"\\n'price_per_sqft' feature successfully created and rounded.\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6: Outlier Removal ---\n",
    "\n",
    "# 6A: Remove Impossible Ratios (total_sqft/bhk < 300)\n",
    "# Assumes 300 sq.ft. is the minimum realistic space per BHK.\n",
    "df = df[~(df['total_sqft']/df['bhk'] < 300)]\n",
    "Y_target = Y_target[df.index] # Synchronize Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6B: Remove Price Outliers (based on std dev of price_per_sqft grouped by location)\n",
    "def remove_price_per_sqft_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('location'):\n",
    "        # Calculate mean (m) and standard deviation (st) for the current location\n",
    "        m = np.mean(subdf['price_per_sqft'])\n",
    "        st = np.std(subdf['price_per_sqft'])\n",
    "        \n",
    "        # Filter for data points that are within 1 standard deviation of the mean\n",
    "        # We only keep points where price_per_sqft is between m-st and m+st\n",
    "        reduced_df = subdf[(subdf['price_per_sqft'] > (m-st)) & (subdf['price_per_sqft'] <= (m+st))]\n",
    "        \n",
    "        # Append the cleaned sub-DataFrame back to the main output\n",
    "        df_out = pd.concat([df_out, reduced_df], ignore_index=False)\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows after Outlier Removal (sqft/bhk and price/sqft): 9274 (Lost 3182 rows)\n",
      "\n",
      "--- Data is now Cleaned and Ready for Modeling ---\n"
     ]
    }
   ],
   "source": [
    "# Run the outlier removal and synchronize Y_target\n",
    "initial_rows_outlier = df.shape[0]\n",
    "df = remove_price_per_sqft_outliers(df)\n",
    "Y_target = Y_target[df.index] # Re-sync Y_target again\n",
    "\n",
    "print(f\"\\nRows after Outlier Removal (sqft/bhk and price/sqft): {df.shape[0]} (Lost {initial_rows_outlier - df.shape[0]} rows)\")\n",
    "print(\"\\n--- Data is now Cleaned and Ready for Modeling ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X) shape after encoding: (9274, 773)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Feature Encoding (One-Hot Encoding for 'location')\n",
    "# 1. Start with df and drop only the temporary 'price_per_sqft' column.\n",
    "X = df.drop(['price_per_sqft'], axis='columns') \n",
    "# 2. pd.get_dummies() automatically encodes 'location' and leaves numerical columns.\n",
    "X = pd.get_dummies(X, drop_first=True) \n",
    "\n",
    "print(f\"Features (X) shape after encoding: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog1p(Y_target) \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Split the data 80% for training, 20% for testing\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, Y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 8: Splitting and Transformation\n",
    "\n",
    "# Apply Log transformation to the Target (Y)\n",
    "Y = np.log1p(Y_target) \n",
    "\n",
    "# Split the data 80% for training, 20% for testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
